"""
MRNetæ¨¡åž‹ - ç”¨äºŽåŒ»å­¦å½±åƒå¤šæ ‡ç­¾åˆ†ç±»
æ”¹ç¼–è‡ªæ–¯å¦ç¦MRNetï¼Œé€‚é…3DåŒ»å­¦å½±åƒå’Œå¤šæ ‡ç­¾åˆ†ç±»
"""

from __future__ import annotations
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import models


# ==================== åŽŸå§‹MRNet (2Dåˆ‡ç‰‡ç‰ˆæœ¬) ====================
class MRNet2D(nn.Module):
    """
    åŽŸå§‹MRNetæž¶æž„
    è¾“å…¥ï¼š2Dåˆ‡ç‰‡åºåˆ— [B, num_slices, C, H, W]
    è¾“å‡ºï¼šæ ‡ç­¾é¢„æµ‹
    """
    def __init__(
        self,
        num_classes: int = 1,
        backbone: str = 'alexnet',
        pretrained: bool = True,
        dropout: float = 0.5,
    ):
        """
        Args:
            num_classes: è¾“å‡ºç±»åˆ«æ•°
            backbone: éª¨å¹²ç½‘ç»œ ('alexnet', 'resnet18', 'resnet34')
            pretrained: æ˜¯å¦ä½¿ç”¨ImageNeté¢„è®­ç»ƒ
            dropout: Dropoutæ¦‚çŽ‡
        """
        super().__init__()
        
        # é€‰æ‹©éª¨å¹²ç½‘ç»œ
        if backbone == 'alexnet':
            self.feature_extractor = models.alexnet(pretrained=pretrained).features
            feature_dim = 256
        elif backbone == 'resnet18':
            resnet = models.resnet18(pretrained=pretrained)
            self.feature_extractor = nn.Sequential(*list(resnet.children())[:-2])
            feature_dim = 512
        elif backbone == 'resnet34':
            resnet = models.resnet34(pretrained=pretrained)
            self.feature_extractor = nn.Sequential(*list(resnet.children())[:-2])
            feature_dim = 512
        else:
            raise ValueError(f"Unsupported backbone: {backbone}")
        
        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))
        self.dropout = nn.Dropout(p=dropout)
        self.fc = nn.Linear(feature_dim, num_classes)
    
    def forward(self, x):
        """
        Args:
            x: [B, num_slices, C, H, W] - batch of slice series
        
        Returns:
            logits: [B, num_classes]
        """
        batch_size, num_slices = x.shape[0], x.shape[1]
        
        # å°†æ‰€æœ‰åˆ‡ç‰‡å±•å¹³å¤„ç†
        x = x.view(-1, *x.shape[2:])  # [B*num_slices, C, H, W]
        
        # ç‰¹å¾æå–
        features = self.feature_extractor(x)  # [B*num_slices, feature_dim, H', W']
        
        # å…¨å±€å¹³å‡æ± åŒ–
        features = self.avg_pool(features)  # [B*num_slices, feature_dim, 1, 1]
        features = features.view(batch_size, num_slices, -1)  # [B, num_slices, feature_dim]
        
        # Max poolingèšåˆæ‰€æœ‰åˆ‡ç‰‡ï¼ˆMRNetæ ¸å¿ƒï¼‰
        features = features.max(dim=1)[0]  # [B, feature_dim]
        
        # åˆ†ç±»
        features = self.dropout(features)
        logits = self.fc(features)  # [B, num_classes]
        
        return logits


# ==================== 3Dä½“ç§¯ç‰ˆæœ¬çš„MRNet ====================
class MRNet3D(nn.Module):
    """
    MRNetæ”¹ç¼–ä¸º3Dç‰ˆæœ¬
    è¾“å…¥ï¼š3Dä½“ç§¯ [B, C, D, H, W]
    æ ¸å¿ƒæ€æƒ³ï¼šæ²¿æŸä¸ªè½´æå–åˆ‡ç‰‡ â†’ ç‹¬ç«‹å¤„ç† â†’ Max Poolingèšåˆ
    """
    def __init__(
        self,
        spatial_dims: int = 3,
        in_channels: int = 1,
        out_channels: int = 4,
        slice_axis: int = 2,  # 0=æ·±åº¦, 1=é«˜åº¦, 2=å®½åº¦
        backbone_2d: str = 'resnet18',
        pretrained: bool = False,
        dropout: float = 0.5,
    ):
        """
        Args:
            spatial_dims: å¿…é¡»ä¸º3
            in_channels: è¾“å…¥é€šé“æ•°
            out_channels: è¾“å‡ºç±»åˆ«æ•°
            slice_axis: æ²¿å“ªä¸ªè½´æå–åˆ‡ç‰‡ (0, 1, 2)
            backbone_2d: 2Déª¨å¹²ç½‘ç»œ
            pretrained: æ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒï¼ˆæ³¨æ„ï¼š3DåŒ»å­¦å½±åƒé€šå¸¸ä¸ºå•é€šé“ï¼‰
            dropout: Dropoutæ¦‚çŽ‡
        """
        super().__init__()
        
        assert spatial_dims == 3, "MRNet3D only supports 3D input"
        self.slice_axis = slice_axis
        
        # å¦‚æžœè¾“å…¥æ˜¯å•é€šé“ï¼Œéœ€è¦è½¬æ¢ä¸º3é€šé“ä»¥é€‚é…ImageNeté¢„è®­ç»ƒ
        self.channel_adapter = None
        if in_channels == 1 and pretrained:
            self.channel_adapter = nn.Conv2d(1, 3, kernel_size=1)
        
        # 2Déª¨å¹²ç½‘ç»œ
        if backbone_2d == 'alexnet':
            backbone = models.alexnet(pretrained=pretrained)
            self.feature_extractor = backbone.features
            feature_dim = 256
        elif backbone_2d == 'resnet18':
            backbone = models.resnet18(pretrained=pretrained)
            # å¦‚æžœæ˜¯å•é€šé“ä¸”ä¸ç”¨é¢„è®­ç»ƒï¼Œä¿®æ”¹ç¬¬ä¸€å±‚
            if in_channels == 1 and not pretrained:
                backbone.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)
            self.feature_extractor = nn.Sequential(*list(backbone.children())[:-2])
            feature_dim = 512
        elif backbone_2d == 'resnet34':
            backbone = models.resnet34(pretrained=pretrained)
            if in_channels == 1 and not pretrained:
                backbone.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)
            self.feature_extractor = nn.Sequential(*list(backbone.children())[:-2])
            feature_dim = 512
        else:
            raise ValueError(f"Unsupported backbone: {backbone_2d}")
        
        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))
        self.dropout = nn.Dropout(p=dropout)
        self.fc = nn.Linear(feature_dim, out_channels)
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        Args:
            x: [B, C, D, H, W]
        
        Returns:
            logits: [B, out_channels]
        """
        batch_size = x.shape[0]
        
        # æ²¿æŒ‡å®šè½´æå–åˆ‡ç‰‡
        if self.slice_axis == 0:
            # æ²¿æ·±åº¦è½´ï¼š[B, C, D, H, W] -> [B, D, C, H, W]
            x = x.permute(0, 2, 1, 3, 4)
            num_slices = x.shape[1]
            x = x.contiguous().view(-1, *x.shape[2:])  # [B*D, C, H, W]
        elif self.slice_axis == 1:
            # æ²¿é«˜åº¦è½´ï¼š[B, C, D, H, W] -> [B, H, C, D, W]
            x = x.permute(0, 3, 1, 2, 4)
            num_slices = x.shape[1]
            x = x.contiguous().view(-1, *x.shape[2:])  # [B*H, C, D, W]
        elif self.slice_axis == 2:
            # æ²¿å®½åº¦è½´ï¼š[B, C, D, H, W] -> [B, W, C, D, H]
            x = x.permute(0, 4, 1, 2, 3)
            num_slices = x.shape[1]
            x = x.contiguous().view(-1, *x.shape[2:])  # [B*W, C, D, H]
        
        # é€šé“é€‚é…ï¼ˆå¦‚æžœéœ€è¦ï¼‰
        if self.channel_adapter is not None:
            x = self.channel_adapter(x)  # [B*num_slices, 3, H, W]
        
        # ç‰¹å¾æå–
        features = self.feature_extractor(x)  # [B*num_slices, feature_dim, H', W']
        
        # å…¨å±€å¹³å‡æ± åŒ–
        features = self.avg_pool(features).squeeze(-1).squeeze(-1)  # [B*num_slices, feature_dim]
        features = features.view(batch_size, num_slices, -1)  # [B, num_slices, feature_dim]
        
        # ðŸŒŸ æ ¸å¿ƒï¼šMax poolingèšåˆï¼ˆMRNetçš„ç²¾é«“ï¼‰
        features = features.max(dim=1)[0]  # [B, feature_dim]
        
        # åˆ†ç±»
        features = self.dropout(features)
        logits = self.fc(features)  # [B, out_channels]
        
        return logits


# ==================== çº¯3Då·ç§¯ç‰ˆæœ¬ ====================
class MRNet3DConv(nn.Module):
    """
    ä½¿ç”¨3Då·ç§¯çš„MRNetå˜ä½“
    ä¸ä¾èµ–2Dé¢„è®­ç»ƒæƒé‡ï¼Œå®Œå…¨ä»Žå¤´è®­ç»ƒ
    """
    def __init__(
        self,
        spatial_dims: int = 3,
        in_channels: int = 1,
        out_channels: int = 4,
        base_channels: int = 32,
        dropout: float = 0.5,
    ):
        super().__init__()
        
        # 3Dç‰¹å¾æå–å™¨ï¼ˆç±»ä¼¼AlexNetçš„ç»“æž„ï¼‰
        self.feature_extractor = nn.Sequential(
            # Conv1
            nn.Conv3d(in_channels, base_channels, kernel_size=7, stride=2, padding=3),
            nn.BatchNorm3d(base_channels),
            nn.ReLU(inplace=True),
            nn.MaxPool3d(kernel_size=3, stride=2, padding=1),
            
            # Conv2
            nn.Conv3d(base_channels, base_channels * 2, kernel_size=5, padding=2),
            nn.BatchNorm3d(base_channels * 2),
            nn.ReLU(inplace=True),
            nn.MaxPool3d(kernel_size=3, stride=2, padding=1),
            
            # Conv3
            nn.Conv3d(base_channels * 2, base_channels * 4, kernel_size=3, padding=1),
            nn.BatchNorm3d(base_channels * 4),
            nn.ReLU(inplace=True),
            
            # Conv4
            nn.Conv3d(base_channels * 4, base_channels * 4, kernel_size=3, padding=1),
            nn.BatchNorm3d(base_channels * 4),
            nn.ReLU(inplace=True),
            
            # Conv5
            nn.Conv3d(base_channels * 4, base_channels * 2, kernel_size=3, padding=1),
            nn.BatchNorm3d(base_channels * 2),
            nn.ReLU(inplace=True),
            nn.MaxPool3d(kernel_size=3, stride=2, padding=1),
        )
        
        self.avg_pool = nn.AdaptiveAvgPool3d((1, 1, 1))
        self.dropout = nn.Dropout(p=dropout)
        self.fc = nn.Linear(base_channels * 2, out_channels)
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        features = self.feature_extractor(x)
        features = self.avg_pool(features).squeeze(-1).squeeze(-1).squeeze(-1)
        features = self.dropout(features)
        logits = self.fc(features)
        return logits


# ==================== è½»é‡çº§ç‰ˆæœ¬ï¼ˆæŽ¨èç”¨äºŽå°æ•°æ®é›†ï¼‰====================
class LightMRNet(nn.Module):
    """
    è½»é‡çº§MRNet
    ä¸“ä¸ºå°æ•°æ®é›†è®¾è®¡ï¼ˆå¦‚æ‚¨çš„760æ ·æœ¬ï¼‰
    """
    def __init__(
        self,
        spatial_dims: int = 3,
        in_channels: int = 1,
        out_channels: int = 4,
        base_channels: int = 16,
        dropout: float = 0.5,
    ):
        super().__init__()
        
        # ç®€åŒ–çš„3Dç‰¹å¾æå–
        self.features = nn.Sequential(
            nn.Conv3d(in_channels, base_channels, kernel_size=7, stride=2, padding=3),
            nn.BatchNorm3d(base_channels),
            nn.ReLU(inplace=True),
            nn.MaxPool3d(kernel_size=3, stride=2, padding=1),
            
            nn.Conv3d(base_channels, base_channels * 2, kernel_size=3, padding=1),
            nn.BatchNorm3d(base_channels * 2),
            nn.ReLU(inplace=True),
            nn.MaxPool3d(kernel_size=2, stride=2),
            
            nn.Conv3d(base_channels * 2, base_channels * 4, kernel_size=3, padding=1),
            nn.BatchNorm3d(base_channels * 4),
            nn.ReLU(inplace=True),
            nn.MaxPool3d(kernel_size=2, stride=2),
        )
        
        self.avg_pool = nn.AdaptiveAvgPool3d((1, 1, 1))
        self.classifier = nn.Sequential(
            nn.Dropout(dropout),
            nn.Linear(base_channels * 4, base_channels * 2),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout),
            nn.Linear(base_channels * 2, out_channels)
        )
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        x = self.features(x)
        x = self.avg_pool(x).flatten(1)
        x = self.classifier(x)
        return x